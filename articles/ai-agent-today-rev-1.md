---
title: "【要更新】AI エージェント 大全！ 最新状況が 包括的・網羅的・具体的 にわかる（2025年X月版）"
emoji: "🤖"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AIエージェント", "LLM", "AI", "AIサービス", "事例" ]
published: false
---

:::message alert
**マルチエージェント・システム と カスタム AI アシスタント構築環境 の説明が混在しているので、大幅に手直しが必要**
:::

<!--------------------------------------------------------------------------------------------------------------------->
## 3行まとめ
- 複数の意味で使われる「AI エージェント」が、それぞれどういったものなのか具体的にわかる
- 動きの早い AI エージェント の現時点で最新の状況が、包括的かつ網羅的・具体的にわかる
- 今後、技術発展のビジョンを議論していくための下準備ができる


<!--------------------------------------------------------------------------------------------------------------------->
## AI エージェント の大胆な未来ビジョン妄想の前に

これから数回にわたって「AI エージェント」関連技術開発の今後の方向性や、やや大胆な未来ビジョンのアイデアを書き留めていこうと思いますが、まずはその最初の下準備として、**AI エージェント 技術の現在位置を具体例を通して確認** しておきたいと思います。

なお、**この文章、非常に長い** です…　本来は、各章をそれぞれ１つの投稿に分割すべき分量なのですが、僕個人として、どうしても一箇所で AI エージェント関連の最新情報を蓄積した場所が欲しく、そして情報のアップデートもそうした方が楽なので、こういった感じになっちゃいました…

お忙しい方は（たぶん皆さんそうでしょう）**興味がある部分だけつまみ読み** したり、**章ごとに分けて読んだり** してください。

なお、[**猛烈に未来を感じさせるという点で特にオススメなのは、Anthropic のパソコン操作自動化のデモ「Computer Use」**](#anthropic%EF%BC%9Acomputer-use-%2F-model-context-protocol) です。まだご覧になったことがない方は、[**ぜひチェック**](#anthropic%EF%BC%9Acomputer-use-%2F-model-context-protocol)してみてください！

<!--------------------------------------------------------------------------------------------------------------------->
## AI エージェント を理解する際の注意点

このドキュメントは、**現時点での「AI エージェント」に関して得られる最新の情報を、網羅的・包括的・具体的 にまとめる** ことを目標にしています（欲張りです… そんなわけで長いです…）

現時点で「AI エージェント」について学んだり情報にキャッチアップしたりしようとする際には、注意事項が２点あります：

- **「AI エージェント」という言葉が、ニュアンスの異なる３つ（もしくは４つ）の意味で使われている**（なので混乱をきたしやすい）
- **現在 IT業界で最も注目されているトピックの１つであり、進化・変化のスピードが異様に早い**

「[**時代は 生成 AI から AI エージェントへ**](https://www.mri.co.jp/knowledge/opinion/2024/202412_1.html)」なんて言われているここ最近、**「AI エージェント」** という言葉は残念ながら [**バズワード化**](https://mba.globis.ac.jp/about_mba/glossary/detail-19753.html) してしまっており、AI 関連製品のマーケティングで乱用される傾向にあります。

そんな経緯もあってか、僕が把握しているだけでも３種類（もしくは４種類）の少し違ったニュアンスでの「AI エージェント」という言葉の使い方があります（これが初学者が混乱する理由の１つだと思っています）。

そこで以下では、**それら複数の意味で使われる「AI エージェント」が、それぞれ具体的にどういったものなのか、製品例を通して具体的に説明します**（どれが間違った使い方、というのではなく、どれも一般的に受け入れられています）。

また、極めて動きの早い AI エージェント 界隈ですが、情報をまとめるにあたっては、**2025年2月 時点での最新情報となるよう心がけました**。

それでは、それぞれの AI エージェントについて、イメージのしやすさ重視で、実例からやや詳しく取り上げていきます。

> **もし「今話題となっている AI エージェント」の現状や要点 だけを知りたい場合は、[こちらの最後の方の節まで読み飛ばしてください](#ai-%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88%E6%A7%8B%E7%AF%89%E3%83%97%E3%83%A9%E3%83%83%E3%83%88%E3%83%95%E3%82%A9%E3%83%BC%E3%83%A0%EF%BC%9A%E4%B8%BB%E8%A6%81%E3%83%97%E3%83%AC%E3%83%BC%E3%83%A4%E3%83%BC%E3%81%AE%E7%8F%BE%E7%8A%B6)**。

<!-- ![robot-marching](/images/ai-agent-today-rev-1/robots-marching.png =600x) -->

<!-- ![robots-dancing](/images/ai-agent-today-rev-1/robots-dancing.png =600x) -->

<!-- ![robot-marching](/images/ai-agent-today-rev-1/robots-discussing.png =600x) -->

![robot-marching](/images/ai-agent-today-rev-1/robots-at-table.png =600x)



<!--------------------------------------------------------------------------------------------------------------------->
# AI エージェント とは？

一般的には **「特定の目標を達成するために構築された AI システム」** のことをいいます。特に最近は [LLM（Large Language Model：大規模言語モデル）](https://www.nri.com/jp/knowledge/glossary/llm.html)を基盤技術として用いることで、爆発的な進化を遂げています。

> 「ここ最近話題の AI エージェント」についてのより厳密な定義は、[最後の方](#%E4%BB%8A%E7%9A%84%E3%81%AA-ai%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88%E3%81%AE%E5%AE%9A%E7%BE%A9%E3%81%A8%E3%81%9D%E3%81%AE%E5%AE%9F%E7%8F%BE%E6%96%B9%E6%B3%95%E3%81%AE%E8%A6%81%E7%82%B9) にあります。

典型的な AI エージェントのイメージとしては、たとえば **「マーケティング AI エージェント」** なんかが良く挙げられます。このエージェントは、マーケンティングに関する **専門知識** とともに、タスクの遂行に必要な、売上・在庫 DB や CRM システムなど、**外部ツールへのアクセスができる仕組み** を持ち、**それらを駆使して、与えられた指示（プロンプト）を遂行** します。外部ツール呼び出しの仕組みとしては、通常 LLM の「[**Tool Calling**](https://qiita.com/xxyc/items/f22890288d39a65e725d)」を使います。

AI エージェント技術は爆速で進化中なのですが、「AI エージェント」と言ったとき、現時点では、ややニュアンスの異なる以下の３つの意味で使われています：

- **特定用途アプリ中に組み込まれた 専用 AI エージェント（完パケ AI エージェント）**
- **AI エージェント部品の構築や、それらを複数連携することによって 新サービスを組み上げるステムにおける、個々の AI エージェント部品**
- **個々の AI エージェント（AI 機能）を組み合わせて構築した システム全体としての AI エージェント**

「完パケ AI エージェント」（僕の造語）は、昨年とても盛り上がりました。今でも話題はつきません。

**「複数の AI エージェント（AI 機能）部品 を組み合わせるシステム構築手法」** と **「構築したシステム全体としての AI エージェントの実務への適用」** は、今まさに盛り上がっている話です。

以下では、それぞれについて順に、具体例を示しながら説明します。

> なお人によっては、汎用の AI チャット「[Copilot](https://copilot.microsoft.com/)」や「[Gemini](https://gemini.google.com/app?hl=ja)」なんかのことも AI エージェントと呼んだりしますね。それも加えると「AI エージェント」という言葉は、４つの違ったニュアンスで使われています。これが初学者の混乱の元、概念把握の難しさの原因になってたりすると思います。


## 特定用途向け専用 AI エージェント

この種の AI エージェントは、通常１つの独立したアプリやサービスの実現機能という位置付けです。このようなアプリやサービス自体も、（広義の）AI エージェントと呼ばれることがあります。

具体的にイメージしやすいように、その代表的な例として、話題のサービス「[**Replit**]([text](https://replit.com/))」と「[**Reply Guy**]([text](https://replyguy.com/))」を簡単にご紹介します。

![replit-replyguy](/images/ai-agent-today-rev-1/replit-replyguy.png =600x)


<!--------------------------------------------------------------------------------------------------------------------->
### Replit エージェント：AI でアプリを自動生成

これは [**Replit**](https://replit.com/) で提供されるのは自動プログラミング・AI エージェントで、2024年11月のアップデートによって、**「本当に」AI がアプリ一式（フロントエンド、バックエンド、通信プロトコル、DBスキーマも含めて）を自動生成できる** ようになって、[**猛烈に話題になった**](https://qiita.com/kobayashi-fuuki/items/33a0deb754c97093b317)サービスです。

実際に僕も使ってみましたが、本当に自動で、しかも見栄えの良い（ちゃんとデザインがある程度入った）ものがでてきます！ 

たとえば、以下のようなプロンプトを出すと…

*「簡単な AIチャット・アプリを作って。画面は２つ：ログイン画面とチャット画面。チャット画面の左側にはチャットの履歴、右側には現在進行中のチャットのやり取りを表示。LLMには 〜 を使って…」*

AI が試行錯誤しつつ（時には仕様の確認をユーザに求めつつ、試しに実行しつつエラーが起きたらそれを自動で解決しつつ）、数分で、下のスクショのようなアプリができました。コーディング全くなし。AI エージェントに指示を与えただけです！
> ユーザ登録・ログイン処理もそれなりにしてますし、チャットの履歴もちゃんと残ります。DB には サーバレスな PostgreSQL サービスである [Neon](https://neon.tech/) を使用（Replitで利用できるDBの種類には制限があります）。なお、ブラウザで開くエディター画面にある「Deploy」ボタンを押すだけで、簡単にデプロイでき、公開用の URL が発行されます。

![replit-agent](/images/ai-agent-today-rev-1/replit-agent.png =600x)

この Replit のような AI利用サービス自体を「（広義の）AI エージェント」と呼ぶこともあります。

以下ではそのような例をもう一つ紹介します。

> Replit の能力にはあまりに驚愕したので、ちょっと使い込んでみました。そしたら限界も見えてきました。その限界は、要は LLM の苦手なことと同じで、既存の例が豊富なものは（学習素材が多いものは）かなりの精度で仕上げてくるのですが、ちょっと凝ったこと、例えば、上の例では、チャットの表示で数式の TeX 表記が処理できるように 後で改良したのですが、その改良部分は全自動では完成せず（一応動くけど細かい不備があったり、例えば最後の数式が変換されないとか）、AIに修正を指示しても、コードを変にこねくり回し始めてラチかあがなくなったので（ちゃんと対処できないくせに無理して応えようとしてのハルシネーション禍？）、最後は自分の手で調整しました。でも逆に言えば、９割９分は全自動でできました。僕が知らないようなライブラリーを器用に使って、僕より遥かにキレイなコードを書いて…。修正時には搭載の AI に、そのライブラリの使い方の指南を受たりもできました。ドキュメンテーションも助かります。「README.md 書いて」と言えば、無難な初稿を出してきます。仕様書も書いてくれます。テストコードも諸設定から初版の生成までしてくれます（モック・サーバのコード生成も含めてです）。こんな感じで、Replit Agent を使うと、まさに爆速でプロトタイピングできちゃいます！（なおアプリ自動生成界隈では、他にも [bolt.new](https://bolt.new/) とか [v0](https://v0.dev/) とかも話題ですが、まだ実際に試せていません…）


<!--------------------------------------------------------------------------------------------------------------------->
### ReplyGuy Agent：SNSの投稿で宣伝に最適なものを見つけて自動リプライ

もう一つの例として、内部動作が想像しやすい [**ReplyGuy**](https://replyguy.com/) を紹介します。
「あなたのアプリや製品の売上を自動的に伸ばすため、オンライン上で最適な製品紹介の機会を見つけ出す AI エージェント」です。

> ちょっと evil な感じでアレですが…
> 
![replyguy](/images/ai-agent-today-rev-1/replyguy.png =500x)

どんなことをするエージェントかというと…

1. 宣伝したいアプリや製品に関連するキーワードを指定すると
2. インターネットを監視し、SNS等で希望のキーワードにマッチする投稿を探し出して
3. AI が、対象の製品を紹介に使えそうな、質の高い関連投稿を選別して
4. その投稿に対して AI が自動的に、「役立つ情報」という文脈で、自然な会話の中に製品紹介を織り交ぜて返信する

たとえば、
*「通勤中にニュースを聞くために、ブラウザで開いたニュース・ページを読み上げさせるいい方法はないかな〜？」* 
とかいった投稿に対して 
*「私もニュースは聞くのが好き。おんなじね。いくつかツールを試したけど、AnySpeech がオススメ。変換早いし声も良いの」* 
とか、自動返信するという…

低予算で激務なWebマーケティングに携わっている人にとっては、たぶん夢のような相棒となるでしょう。

> こんな使い方が広まるから、AI によってネット上の言論空間が余計に… とか言いたくなるのをグッと堪えて…

以上、特定用途向け専用AI エージェント（完パケ AI エージェント）について、具体例とともに説明しました。イメージがはっきりしたのではないかと思います。

この類の AI エージェント（AIツール）には他にどのようなものがあるのかご興味がある方は、例えば以下の記事をご参照ください：
- [AI ツール一覧：最新の AI ツール55選！無料おすすめランキング比較（マーケMEMO 2024/11）](https://www.marke-media.net/whitepaper/ai-tool/)

繰り返しになりますが、一部の人は、こういった AI サービス自体を「AI エージェント」と呼んだりします（例えば「今 AI エージェントで最もアツイのは Replit だ」とか）。

次は、もう少し違った意味の、いわば「伝統的な AI エージェント」でありつつ「今盛り上がっている AI エージェント」について、こちらも具体例をあげて説明します。


<!--------------------------------------------------------------------------------------------------------------------->
## サービスを組み上げる部品としての AI エージェント

こちらの方が昔からある伝統的な「AI エージェント」の用法で、特にアカデミックな文献での使われ方は概ねこちらです。

発想としては、大きなタスクを AI に処理させること考えた時「LLM に長いプロンプトを一発食わせて あとは LLM の裁量に丸投げする」のではなく、タスクの進め方の大枠を明示的に定義する、つまり、作業内容を複数のサブタスクに分解し、それぞれのサブタスクを別個のAI エージェントに割り振り、それらエージェント群を連携させて元のタスクを遂行させる、というアプローチです。

> プロンプトが長く複雑になると、処理が狙い通りになるまでに必要なプロンプトの試行回数が多くなりがちです。また LLM が混乱したり [ハルシネーション]([text](https://officebot.jp/columns/basic-knowledge/hallucination-strategy/)) を起こしたりして、遂行の質が劣化する可能性が高まります。加えて LLM がバージョンアップ等でその挙動が微妙に変わってしまうと 思うように動かなくなってしまうこともあります。
> > 人間の世界と同じですね。いくら有能で博識な人でも、例えばマーケティングの全部の側面に同時に対応しろ、と言われても、パフォーマンスは出しにくい。LLM も、雑に言って人間の考え方のパターンをコピーしてると言えるので、その辺の傾向も継承していると考えられるかもしれません。

これは、大昔からある大規模タスクに対処するための典型的なアプローチ（後述）の、LLM への流用です。

ただ、単なる流用というだけではなくて、この「小規模 AI（LLM）エージェントを組み合わせてタスクをこなす」ことの利点を示した論文が、Tencent AI Lab の研究者達により 2024年3月に発表され、大いに話題になりました：

[**「小さなLLMエージェントを巧みに組み合わせることで、単一の巨大モデルをも上回る集合的な知性を実現することが可能である」**](https://note.com/panda_lab/n/n1ee06712101e) というものです。

そんなこともあり、現在、関連技術の開発がとても盛んで、実用製品や適用事例がいくつも出ている段階まで来ています。

以下ではまず、「サービスを組み上げる部品としての AI エージェント（LLM エージェント）」を実感をもって理解するために「[**Dify**](https://docs.dify.ai/ja-jp)」を簡単に紹介します。


<!--------------------------------------------------------------------------------------------------------------------->
### Dify： AI エージェントを組み合わせてつくる AI アプリケーション開発フレームワーク

**[Dify](https://dify.ai/jp)** は 2023年4月に初版が公開された、オープンソースのAIアプリケーション開発フレームワークです。とても直感的なユーザ・インターフェイスを介して、特定の処理用にカスタマイズされた LLM（LLMエージェント・AI エージェント）を、簡単なマウス操作で複数組み合わせて、目的のタスクをこなすための「ワークフロー」を構築することができます。この手の開発環境としては先行者なので、後の同様な開発フレームワークの多くに影響を与えています。

使い方の雰囲気をつかむには、こちらのムービーを見ていただくのが早いでしょう：

[![dify-workflow-movie](/images/ai-agent-today-rev-1/dify-workflow-movie.png =500x)](https://github.com/langgenius/dify?tab=readme-ov-file#key-features)

AI エージェント部品は、Difyの世界では、単に「（カスタマイズした）LLM」とか「LLM エージェント」と呼ばれています。

Difyは、前述の「AI エージェントに必須な外部リソースとの連携用ツール」も、膨大な量サポートしています（ムービーでは 0:13 あたり。ツールには「BingWebSearch」とか「Text To Speach」とかがあって、その総数は、実際にざっと数えて現時点で 200種以上でした）。

ムービーで分かるように、LLM とかツールとかのハコをマウス操作で追加＆接続して、連携グラフ「ワークフロー」を作成し、複数の LLMエージェントとツールの動作の組み合わせを方を指定していきます（0:18〜）。

![dify-workflow](/images/ai-agent-today-rev-1/dify-workflow.png =500x)

これを使えば、上述の「ReplyGuy」みたいなサービスは、自分で構築できちゃいそうですね。

ちなみに、上の例のように **エージェントを協調動作** させることを「**オーケストレーション**（orchestration = 複数の要素を調整・統合して 全体として最適な状態を作り出すこと）」と呼ぶこともあります。

> Dify は僕も実際に使ってみたのですが、ワークフローの構築は本当に簡単です… が、最初「コンテキスト」（使ってると設定項目として出てきます）の設定方法の要領がつかめず、ちょっと迷いました。見た目は簡単そうですが、プログラミング（ローコード・プログラミングも含む）とかやったことない人だと（変数の概念を知らないと）簡単には使えないかな…（つまりそこまで楽チンではないです）

コーディングが得意もしくは好きな人は（僕も含めて）、[LangChain](https://www.langchain.com/) とかを使って、上のようなワークフロー（LangGraph）を直接プログラムするでしょうね。ただ、こういった簡易開発ツールの増加は、技術のコモディティ化を推し進めます。それはこういった AI システムを構築できる人の増加、開発価単価の低下、そして利用者の増加を促します。特に、**主要な IT 系プレーヤーがこういったツールに参入してきた今**（後述）、**その流れは加速度的に早まっています**。

> ちなみに僕の妻は、ずっと営業職だったのですが、数年前、アプリ開発者（！）へと、まさかの職種変更しました。超文系の妻がアプリ開発なんて… と思っていましたが、ローコード・プログラミング・ツール（Microsoft PowerApps / PowerAutomation）を使った開発に携わっており、ググったり、Copilotったり、Udemy 観たりしつつ、それなりに開発を進めています。

<!-- このように、（狭義での）AI エージェント（LLMエージェント や カスタムLLM と呼ばれる時もある）を組み合わせて、AI システム（広義の AI エージェント）を構築することは、最近 激アツに盛り上がっています。 -->





<!--------------------------------------------------------------------------------------------------------------------->
### 「マルチエージェント・システム」や「AI オーケストレーション」という用語

ちなみに、上述ような、**複数の AI エージェント（LLM）やアルゴリズムを連携させて、統合的に機能させる技術や手法** のことを、「**マルチエージェント・システム（Multi Agent System：MAS）**」とか、特に最近は「**AI エージェント・オーケストレーション**」、または単に「**AI オーケストレーション**」と呼んだりもします（これも最近のバズワードの１つです）。

その場合、「AI エージェント構築フレームワーク」は、「LLM マルチエージェント・フレームワーク」や「AI オーケストレーション・フレームワーク」とかいう呼び方になります。

「AI オーケストレーション」は最近話題になり出した用語なので、定義には多少ブレがあって、以下の参考文献のような、もう少し高級な定義もあります。ちなみに引用の後半は、その必要性のまとめなのですが、とてもコンサルちっくではありますが、多くの要点が手際よく詰め込まれていて参考になります：

> 参考文献 [**「AIオーケストレーション市場：コンポーネント、用途、技術、展開タイプ、組織規模、エンドユーザー別-2025～2030年の世界予測」**（Global Infornation 2024年10月）](https://www.gii.co.jp/report/ires1570689-ai-orchestration-market-by-component-services.html)によると：
>
> **AIオーケストレーション** とは、**複数のAIシステムとプロセスを統合、管理、自動化し、組織内で調和的に動作させ、それらの総合的なパフォーマンスを最適化するプロセス** を指します。異なるAI技術やデータソース間のシームレスな相互作用を可能にし、業務のサイロ化を減らすため、AI導入の効率性と有効性を最大化するために極めて重要です。AIオーケストレーションの必要性は、AIプロセスを合理化し、スケーラビリティを高め、市場投入までの時間を短縮する能力にあり、金融、医療、小売、製造などのデータ集約型の業界では特に不可欠です。

なお、「マルチエージェント・システム」や「AI オーケストレーション」といった言葉は、他の文献を読む際の用語理解の手助けとして、また情報収集・検索時の利便性を考えてここでご紹介したのですが、
- 「マルチエージェント・システム」という言い方だと、最終的に全体として AI サービスを構築するというニュアンスが弱くなり
- 「AI オーケストレーション」は、用語としては バズワード化 しすぎな印象もあるので

以下では引き続き、もう少し堅実な **「AI エージェント構築フレームワーク」** という言葉を使い続けることにします。

> でもこれだと「複数のAI エージェントが協業して」というニュアンスが出ないのですが、手法よりも目的の方に重きを置くということで…



<!--------------------------------------------------------------------------------------------------------------------->
## AI システム全体としての「AI エージェント」

最初の方で、「AI エージェント」には３つのニュアンスの異なった用法がある、と言いましたが、「AI エージェント構築フレームワーク」のイメージがつかめたところで、その３番目の用法の話をします。

３番目の用法、「**（広義の）AI エージェント**」とは、「**（狭義の）AI エージェント**」（LLMエージェント や カスタムLLM と呼ばれることもある）を組み合わせて構築される、**AI システム** のことを指します。

AI システム全体のことを「AI エージェント」と呼ぶんなら、それは１つ目の **「特定用途アプリ中に組み込まれた 専用 AI エージェント（完パケ AI エージェント）」と何が違うの？** という疑問を持つ方もいるかもですが、違いは、こちらの方は、**利用者に即してカスタマイズされている「オーダーメードな AI エージェント」** であり、他方は「どのユーザでも同じ 既製品」という点です。

AI エージェントがその価値の本領を発揮するのは、**利用者に合わせて高度にカスタマイズされ、利用者の生産性や満足度を最大限に向上した時**です。それを実現するための土台が「AI エージェント構築フレームワーク」だったわけです。つまり、**「AI エージェントのカスタマイゼーション」** が鍵となります。

以降では一旦、**「AI エージェント の歴史」** と **「AI エージェントの可能性を広げた要素技術の進展」** を振り返ります。

その流れを受けて、それ以降の節で、現在の、この AI エージェント進化の激流の中の、Microsoft や Google といった **主要なプレーヤー達が、どういった AI カスタマイゼーション・フレームワークを、どのような狙いで提供しているのか**、具体的に把握することを目指します。



<!--------------------------------------------------------------------------------------------------------------------->
# AI エージェント の歴史

最初の方で、AI エージェントとは **「特定の目標を達成するために構築された AI システム」** とお伝えしましたが、コンピュータが誕生して以来、**人間の知的労働をコンピュータに代行させることは、コンピュータ科学研究者たちの長年の夢** です。

そこで、今までの章を通して、現在の AI エージェントの概要を把握できたこのタイミングで、一旦、AI エージェントの発展の歴史を振り返ってみようと思います（この手の話がうまくまとまった資料を見つけられなかったので、ここに書き留めました）。

この章と次の章（「AI エージェントの可能性を広げた要素技術の進展」）は、基本箇条書きによる情報の羅列、調査結果の自分用覚え書きです。
**長いので、基本、読み飛ばしてください。**

> なお、このドキュメントは、自分の個性が出た方が良いかと思い、基本手で調べて手書きをしているのですが、この章と次の章だけは、AI の力に大いに頼っています。こういった、総論的・網羅的な調査には、個人の思い込みや趣味などのバイアスを避けるためにも、AI の活用先として最適だと思います。
> > ちなみに調査には Anthropic の「Claude for Desktop」を、有料プラン かつ MCP 経由（後述）で Brave ウェブ検索の機能を追加拡張して利用しています。こうすることにより、LLM の学習カットオフ時点（現在利用のバージョンでは 2024年4月）以降の事項についても調査できるようになります。

#### 時代背景

1970年代、AI エージェントに息吹が宿り始めました。
この時期は、メインフレーム から ミニコンピュータ への移行期であり、また集積回路技術の進歩により、コンピュータの小型化と低価格化が進んでいました。1971年は、特にマイクロプロセッサの登場という画期的な出来事があり、コンピュータ技術の民主化への重要な一歩となりました。

まず、「AI エージェント」の研究が芽生え始めた背景を掴むために、同時期のコンピュータ業界の主な出来事を以下にまとめます。今の AI 革命と同じように、コンピュータ関連の重要な理論や技術が次々に登場し、コンピュータ革命がまさに猛烈に進行していた時代でした：
- **1969年**
  - ARPANET が稼働開始（インターネットの起源）
  - UNIX の開発が AT&T ベル研究所でスタート

- **1970年**
  - Intel が DRAM（1103）を発売、メモリ革命が始まる
  - エドガー・カッド が リレーショナル・データベース（RDB）の理論を発表
  - ミニコン（minicomputer）の台頭（DEC PDP-11の発売）

- **1971年**
  - Intelが最初のマイクロプロセッサ4004を発売
  - 電子メールの基本概念が確立

- **1972年**
  - Atari が「PONG」を発売、ビデオゲーム産業の幕開け
  - C 言語の開発が ベル研究所 で本格化

人工知能の分野では、この時期はまだ「推論と探索」を中心とした第１次 AI ブームの終わりに差し掛かっていました。次の扉を開いた代表的なプロジェクトは「STRIPS」でした。

#### 黎明期

以下では「STRIPS」以降の AI エージェント発展の歴史を、主要なプロジェクトを通して見てみます（90年代にこの手の研究は一度下火になります）：

- [**STRIPS**](https://en.wikipedia.org/wiki/Stanford_Research_Institute_Problem_Solver) (1971年)
  - Stanford Research Institute で開発された初期の自動計画システム
  - 目標達成のための行動シーケンスを自動的に計画する能力を持つ
  - 現代の AI プランニングシステムの基礎となる重要な概念を確立
  - 前提条件と効果を明示的に定義し、論理的な行動計画を生成

- [**SOAR**](https://soar.eecs.umich.edu/) (1983年)
  - John Laird、Allen Newell、Paul Rosenboomによって開発
  - 汎用AI（AGI）を目指した認知アーキテクチャ
  - 問題解決、学習、長期記憶の統合を実現
  - 現在も研究・開発が続けられている長期プロジェクト

- [**BDI Agent**](https://link.springer.com/referenceworkentry/10.1007/978-0-387-39940-9_192) (1987年)
  - Belief-Desire-Intention（信念-欲求-意図）モデルに基づくエージェント
  - Michael Bratmanの理論を基に、実践的な推論システムとして実装
  - エージェントの意思決定プロセスに人間の思考モデルを適用
  - 現代のマルチエージェントシステムに大きな影響を与えた

- [**IBM Watson**](https://www.ibm.com/watson) (2006年 開発開始、2011年公開)
  - 自然言語処理と質問応答に特化した AI システム
  - 大規模な知識ベースと複数の AI アルゴリズムを統合
  - クイズ番組「Jeopardy!」で人間のチャンピオンに勝利
  - タスク指向の AI エージェントの可能性を示した画期的なシステム

これらの技術は、現代の LLM ベースの AI エージェントとは異なるアプローチを取っていましたが、エージェントの自律性、推論能力、目標指向の行動計画といった重要な概念を確立し、現代の AI エージェント開発に大きな影響を与えています。

#### LLM の登場

そして、LLM（大規模言語モデル）の登場が、AI エージェント研究を再点火します。
LLM の登場は、以下の3段階に整理する事ができます：

- **技術的な登場：2017年**
  - Transformerアーキテクチャの登場（論文「Attention is All You Need」）
    - 2018年：BERT の登場（Google による双方向 Transformer モデル）
    - 2019年：GPT-2 の登場（OpenAI による初めての大規模生成モデル）
- **現代的なLLMの始まり：2020年**
  - GPT-3 の登場：パラメータ数 175B / few-shot 学習能力を実証
- **社会的インパクト：2022年末**
  - ChatGPT：ビジネスでの実用的な活用開始

多くの技術史では、GPT-3 の登場（2020年）を現代的な LLM の起点とする見方が一般的ですが、一般社会における「LLM 時代」の始まりの認識は、明らかに ChatGPT の登場（2022年11月）とされることが多いです。これは、ChatGPT によって LLM の能力が一般ユーザーにも分かりやすい形で示され、実用的な活用が急速に広がったためです。

#### LLM をベースとした AI エージェントの急速な進化

この流れを受けて、2020年以降、AI エージェントに関連する重要な技術革新が急速に始まりました：

- [**WebGPT**](https://openai.com/research/webgpt) (2021年12月、OpenAI)
  - GPT-3をベースに、ウェブブラウジング能力を統合した初期のエージェント
  - 質問に対して、実際のウェブ検索と情報の統合を行える
  - 情報源の引用とともに回答を生成する機能を実装
  - 外部ツールと LLM の統合の先駆けとなった
- [**Chain-of-Thought**](https://arxiv.org/abs/2201.11903) (2022年1月、Google Research)
  - 推論過程を段階的に示す「思考の連鎖」を導入
  - 複雑な問題解決における思考プロセスの可視化を実現
  - ReAct エージェントの基礎となる重要な概念を提供
  - 数学的推論や論理的思考を要するタスクでの性能向上を実証
- [**Constitutional AI**](https://arxiv.org/abs/2212.08073) (2022年4月、Anthropic)
  - LLMに特定の行動原則や制約を組み込む手法を提案
  - エージェントの行動に倫理的な制約を設ける重要性を示した
  - 安全で信頼できるAIエージェントの開発に影響を与えた
- [**Inner Monologue**](https://research.google/pubs/innermonologue-embodied-reasoning-through-planning-with-language-models/) (2022年5月、Google Research)
  - LLMの内部対話による問題解決アプローチを提案
  - 自己修正や推論の改善を行う機能を実装
  - ReAct と並行して発展し、相互に影響を与えた
- [**ReAct**](https://arxiv.org/abs/2210.03629) (2022年7月発表)
  - Google と UC Berkeley の研究チームによって発表された最初期の重要な AI エージェント・フレームワーク
  - Reasoning (推論) と Acting (行動)を組み合わせたアプローチを提案
  - タスクを「観察→思考→行動」のステップに分解して実行する手法を確立
  - 後続の AI エージェントに大きな影響を与えた基礎的なアーキテクチャ
- [**BabyAGI**](https://github.com/yoheinakajima/babyagi) (2023年3月発表)
  - Yohei Nakajima 氏によって開発され、GitHubで公開
  - タスクの自動分解と優先順位付けを行い、サブタスクを生成・実行する機能を実装
  - GPT-4 や Vector Database を活用して、タスクの管理と実行を自律的に行う
  - シンプルながら実用的な自律型 AI エージェントとして注目を集めた
- [**AutoGPT**](https://github.com/Significant-Gravitas/AutoGPT) (2023年4月発表)
  - Significant Gravitas 社によって開発
  - より高度な自律性を持ち、複数のツールを組み合わせて複雑なタスクを実行可能
  - インターネット検索、ファイル操作、コード実行などの機能を統合
  - メモリ管理システムを備え、長期的なタスク実行をサポート
- [**LangGraph**](https://github.com/langchain-ai/langgraph) (2023年12月発表)
  - LangChain チームによって開発された エージェント開発フレームワーク
  - 有向グラフベースのワークフロー管理を特徴とし、より複雑なタスクの制御が可能
  - 状態管理と並列処理を改善し、より効率的なタスク実行を実現
  - エージェント間の協調動作やマルチエージェントシステムの構築を容易にする

この時期は、まだプログラミングによる AI エージェントの開発が主流でした。
オープンソースである「LangChain / LangGraph」 がそのプログラミングに重宝されました。

そして、2023年4月に初版が公開され、オープンソースがゆえ広くサポートを得た「Dify」（上述）を皮切りに、グラフィカルな AI エージェント構築フレームワークが台頭してきます。

<!--------------------------------------------------------------------------------------------------------------------->
# 可能性を広げた LLM 要素技術の進展

「AI エージェント構築フレームワークの現状」の話をする前に、もう一つだけ寄り道を。

AI エージェントの能力を大きく拡張し、より実用的なタスクの実行を可能にした基盤技術について目を通しておくと、AI 技術の進展の方向性と、構築した AI システムの力を実感できます。

以下では、そういった AI エージェントの可能性を広げた要素技術を列挙します。

#### コンテキストウィンドウ（LLM が一度に扱えるテキストの最大長）の拡大：
- [**GPT-3**（2020年）](https://openai.com/blog/gpt-3-apps): 4,096トークン
- [**GPT-3.5**（2022年）](https://openai.com/blog/chatgpt): 4,096トークン
- [**GPT-4**（2023年初期）](https://openai.com/research/gpt-4): 8,192トークン
- [**Claude 2**（2023年7月）](https://www.anthropic.com/news/claude-2): 100k トークン
- [**GPT-4 Turbo**（2023年11月）](https://openai.com/blog/new-models-and-developer-products-announced-at-devday): 128k トークン（日本語・英語ともに標準的な書籍１冊程度）
- [**Claude 2.1** （2023年11月）](https://www.anthropic.com/news/claude-2-1): 200k トークン
- [**Google Gemini 1.5 Pro**（2024年2月）](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/): 1m トークン（5月版で 2mトークン）
- **最新情報：[LLM API Providers Leaderboard - Comparison of over 100 LLM endpoints](https://artificialanalysis.ai/leaderboards/providers)**

#### 視覚・マルチモーダル関連：
- [**OpenAI: DALL-E**（2021年1月）](https://openai.com/blog/dall-e/)
  - テキストから画像を生成する最初の主要なモデル
  - 画像生成の可能性を示した画期的な成果
- [**Google DeepMind: Flamingo**（2022年4月）](https://deepmind.google/discover/blog/tackling-multiple-tasks-with-a-single-visual-language-model/)
  - 画像に関する質問応答が可能なモデル
  - 少数のサンプルからの学習能力を実証
- [**OpenAI: GPT-4V**（2023年9月）](https://platform.openai.com/docs/guides/vision)
  - 画像理解と詳細な分析が可能
- [**Anthropic: Claude 3 Vision**（2024年3月）](https://www.anthropic.com/news/claude-3-family)
  - 高精度な画像理解と分析機能
- [**Google: Gemini Ultra Vision**（2024年初頭)](https://blog.google/technology/ai/google-gemini-ai/)
  - マルチモーダルな理解と生成能力
- **進化の方向性**
  - テキスト、画像、音声の統合的理解、単一モダリティから複数モダリティの統合へ
  - 単方向処理（生成のみ・理解のみ）から双方向処理へ
  - 静的コンテンツから動的コンテンツ（動画）の理解へ
  - 表面的な理解から深い文脈理解・推論へ

### LLM の処理速度の向上：
- [**GPT-3.5**](https://openai.com/blog/chatgpt) 初期状態（〜2023年前半）
  - 応答生成に数十秒、トークン生成速度1-2トークン/秒程度
- [**GPT-3.5 Turbo**（2023年7月）](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)
  - 応答時間が半分程度に短縮、コスト効率も改善
- [**Claude 2.1**（2023年11月）](https://www.anthropic.com/news/claude-2-1)
  - トークン生成速度が約5トークン/秒に向上、長文処理の効率化を実現
- [**Claude 3**（2024年3月）](https://www.anthropic.com/news/claude-3-family)
  - トークン生成速度が最大20トークン/秒に到達、マルチモーダル処理とテキスト処理の両立
- **主な改善要因**：モデルアーキテクチャの最適化、ハードウェア利用効率の向上、並列処理の実現


以上、「AI エージェント の歴史」と「可能性を広げた LLM 要素技術の進展」を駆け足で振り返りました。

この流れを受けて、次の章では、現在のこの AI エージェント進化の激流の中、Microsoft や Google といった **主要なプレーヤー達が、どういった AI カスタマイゼーション・フレームワークを、どのような狙いで提供しているのか**、具体的に把握してみようと思います。


<!--------------------------------------------------------------------------------------------------------------------->
# AI エージェント構築フレームワーク：主要プレーヤーの現状 

「AI エージェント構築フレームワーク」がこれだけ注目されている理由は、**IT系の主要プレーヤーによる AI エージェント 構築（カスタマイぜージョン）環境がひととおり出揃い、それらを用いてカスタマイズした AI エージェントによる業務の効率化の成果が出だしており、市場の大幅な拡大が期待されている** ためです（[詳細は後述](#%E5%8F%82%E8%80%83%E8%B3%87%E6%96%99%EF%BC%9A%E4%BC%81%E6%A5%AD%E5%8B%95%E5%90%91%E3%83%BB%E9%81%A9%E7%94%A8%E4%BA%8B%E4%BE%8B%E3%83%BB%E7%B5%8C%E6%B8%88%E5%8A%B9%E6%9E%9C%E3%83%BBetc.)）。

そこで以下では「AI エージェント構築フレームワーク」について詳しく説明していこうと思うのですが、僕は、概念的な話から入るよりは具体例から入りたい人なので、まずは、各社のフレームワークやサービスの具体例について、やや詳しくみていきます。

AI エージェント構築フレームワークの設計の際、何に着目するか、という点において、各社各様、目の付け所が違って興味深いです。





<!--------------------------------------------------------------------------------------------------------------------->
## Microsoft : Copilot Studio


現在のCopilot Studioの機能：


個別のAIエージェントの作成と管理
Microsoft 365サービスとの統合
プリビルトエージェントの提供
タスク自動化の実現


エージェント間連携に関して：


複数エージェント間の直接的な協調や通信機能は現時点では明示的にサポートされていない
各エージェントは独立して動作し、個別のタスクやワークフローを処理


代替的なアプローチ：


Microsoft TeamsやPower Automateを通じた間接的な連携は可能
ワークフローの中で複数のエージェントを順次実行することは可能


OpenAI への出資や、その技術の Copilot へのアグレッシブな適用で AI まわりで先行ポジションにある Microsoft は、**独自の AI エージェントを ローコ ードで構築するためのツール**「**[Copilot Studio](https://learn.microsoft.com/ja-jp/microsoft-copilot-studio/fundamentals-what-is-copilot-studio)**」を提供しています。2024年11月に AI エージェント作成機能が強化されました。

![microsoft-copilot-studio](/images/ai-agent-today-rev-1/microsoft-copilot-studio.png =300x)


Copilot Studio の特徴をまとめると以下のような感じです；

- **特定のタスク専用の Copilot チャット・ボットを構築** するためのフレームワーク
- **複数のAI エージェントが役割分担を行いながら、協調してタスクを遂行**できる
- **Microsoft のクラウド・サービスとの連携が容易**

つまり、この Microsoft のアプローチで重要な点は、**すでに広く使われている AI チャット「Copilot」を、各種各様の AI エージェントにカスタマイズ** できるようにする、というものです。そうすることにより、今日の Copilot の使い方に慣れた多くのユーザは、同じ雰囲気で社内業務専用 AI エージェントを使い始めることができ、**社内への AI エージェント導入時の 心理的障壁 を格段に下げる** ことができます。一見何の変哲もないアプローチですが、ユーザ心理に配慮しつつ自社の立ち位置の強みを活かしており、良く考えられていると思います。

加えて、Microsoft のクラウド・サービスとの連携が容易なのも猛烈な強みです。すでに膨大な数存在する **Microsoft 365 ユーザ企業なら、蓄積した情報資産の活用が非常に楽**にできます。強みを活かした戦略、抜かりはありません（さすが 米国主要大学のMBA卒業生のトップ達が入りたい企業の最上位のひとつだけのことはあります ← 聞いた話）。
> ちなみに、Microsoft は、将来のビジネスの主役は Microsoft 365 から Copilot（データの蓄積・処理から、その生成の AI での活用）に移ると考えているようで、[「マイクロソフトの Copilot 推しは続く。Microsoft 365を｢Copilot｣に改名（Gizmodo 2025年1月）」](https://www.gizmodo.jp/2025/01/microsoft-office-365-renamed-to-copilot.html) なんていうニュースも入ってきています。

#### Copilot Studio での AI エージェント「独自の Copilot」作成の実際

では、Copilot Studio の実際の使い心地はどんな感じなのでしょうか？
それを知るには、以下のムービー（全体で 46分強・2024年6月 公開）を観るのが早いです。

[![copilot-studio-movie](/images/ai-agent-today-rev-1/copilot-studio-movie.png =500x)](https://www.youtube.com/watch?v=wwHEmAhku2s)

このムービーの僕的な見どころは「**自然言語で Copilot を作る**」デモです（9:30〜）。

ポイントは、**ユーザが慣れている「チャット」だけを通して、専用 AIエージェントを構築している** ところです（これは 2024年11月の機能拡張の１つとのこと）。

- **自然言語で Copilot を作る**（9:30〜）
  - デモでは「市民に提供する補助金の質問に答えられるようなのを作りたい」と入力（現時点では英語のみサポート）
  - ツール側が「どういうふうに支援したいのか文章で説明してくれ」と追加情報を要望
  - 「市役所職員が資料を使って、市民に対して補助金の説明ができるようにしたい」と返答
  - 続いて、口調をどうするかとか、テキストでやり取りをし
  - ツールから「返答にあたっての [**グラウンディング（生成内容の裏付け）**](https://atmarkit.itmedia.co.jp/ait/articles/2403/06/news027.html) の際のデータ・ソースは何か？」と聞かれる
  - そこで、２つの URL を返答する（これらのページの内容を元に生成して返答してくれ、という意味）
  - これで画面下の「I'm Done」ボタン、続いて右上の「Create」ボタンを押せば、カスタム Copilot が出来あがる
  - その後、画面右側の「Playground（遊び場）」でこの Copilot をテストできる
  - 「原油価格高騰に資する助成金をリストアップしてください」と問い合わせると、ナレッジ（与えたURL）の中からデータを引っ張ってきて、文章を生成して返してくれる

たとえば、上述の Dify では、いろいろな機能のハコをキャンバス上に追加したり、それらを繋いだりして AIエージェント（ワークフロー）を構築していたわけですが（それはそれで良く出来ているのですが）、一般人が使うことを考えると、それでもまだ利用開始の障壁は高いです。でもチャットなら、たぶん誰でもすぐに始められます。

あらゆる面で導入障壁を下げることを目指すというこの徹底された姿勢、そこで（ともすると技術者的には華やかさのない）「テキストでのチャット」という UI に着目したのは、ユーザ・ファーストの姿勢が深くチームで共有されていることを示唆しており、関心します（チーム・マネージメントをどうやってるのか興味がある）。

なお、ムービーではこの後、画面のキャンバス上で（グラフィカルに）、フローチャート的な UI（Dify 風、もしくは PowerApps や PowerAutomate 風）を使って、ハコを足したりつなげたりして、カスタム Copilot を作るデモが続きます（17:00〜）。

![copilot-studio-movie-flow](/images/ai-agent-today-rev-1/copilot-studio-movie-flow.png =500x)

まずはチャットベースで Copilot Studio に慣れて、もし込み入ったことをやりたくなったらこっちを使ってね、ということでしょう（ユーザを段階的に慣れさせる… 定石通りです）。

その後、いろいろと込み入った例の説明があった後、「**Copilot Studio のアーキテクチャの説明**」（31:45〜）として、内部ではどのようなコンポーネントがどう連携して動いているのかの説明があります（すでに長くなっているので、ここではこれ以上深入りしないでおきます）。

![copilot-studio-architecture](/images/ai-agent-today-rev-1/copilot-studio-architecture.png =500x)

最後に、AI 適用事例に関して、Microsoft のまとめのページをご紹介して、本節を終わりたいと思います：

- [**「AI エージェントで実現する業務効率化とイノベーション: 日本の最新事例」**（Microsoft 2024年12月）](https://news.microsoft.com/ja-jp/2024/12/18/241218-operational-efficiency-and-innovation-enabled-by-ai-agents-latest-case-studies-from-japan/)


#### その他の AI エージェント開発フレームワーク

Microsoft は実はあと２つ別の AI エージェント開発フレームワーク を持っています：

- [**Microsoft: Semantic Kernel**（公開：2023年3月）](https://devblogs.microsoft.com/semantic-kernel/introducing-semantic-kernel/)
  - オープンソースである（[github リポジトリ](https://github.com/microsoft/semantic-kernel)）
  - アプリケーションへの AI 機能の組み込みを容易にする
  - C#、Python、Java で利用可能
  - 対象：アプリケーション開発者・オープンコミュニティ（ビジネスユーザー、業務アプリケーション開発者ではない）

- [**AutoGen**（公開：2023年9月）](https://www.microsoft.com/en-us/research/project/autogen/)
  - オープンソースである（[github リポジトリ](https://github.com/microsoft/autogen)）
  - 複数のAIエージェントの協調動作に特化
  - Microsoft Research が主導している
  - 対象：研究者、先端技術の実験的実装を行う開発者


しかしながら、Semantic Kernel は「製品展開を目指す」というよりも、「開発者コミュニティを巻き込んだオープンな技術基盤の確立」を目指しており、また AutoGen は、Microsoft Research が主導する研究プロジェクトとしての位置づけのようです。

残念ながら、現時点では 両方とも Microsoft のメインストリームではないと思われるので（ノウハウ等は流用されるでしょうが）、ここでの詳細な紹介は割愛しました。

ご興味のある方は、例えば以下のドキュメントを読むと、その雰囲気がよくわかります：
- [「利用者目線での Semantic Kernel v1 入門」（Zenn 2024年4月）](https://zenn.dev/microsoft/articles/semantic-kernel-v1-004)
- [「Autogen StudioでAIプロダクト開発チームを作る（Zenn 2024年12月）」](https://zenn.dev/2bo/articles/ai-product-team-by-autogen)

<!-- [マイクロソフトは、Copilot と AI エージェントを組み合わせる](https://news.microsoft.com/ja-jp/2024/12/18/241218-operational-efficiency-and-innovation-enabled-by-ai-agents-latest-case-studies-from-japan/) -->

<!-- [Microsoft Copilot for Azure とは](https://www.avepoint.com/jp/blog/microsoft-365-ja/about-copilot-for-azure) -->

<!-- Azure を使った設計や運用、クラウド管理の最適化、トラブルシューティングを Copilot により効率的に行えるようにした -->

<!-- [生成オーケストレーションの使用についてよくあるご質問](https://learn.microsoft.com/ja-jp/microsoft-copilot-studio/faqs-generative-orchestration) -->

<!-- AutoGen -->

<!-- [AutoGen - Microsoft Research](https://www.microsoft.com/en-us/research/project/autogen/) -->

<!-- [AutoGen Studio - Getting Started](https://microsoft.github.io/autogen/0.2/docs/autogen-studio/getting-started/) -->

<!-- [Autogen StudioでAIプロダクト開発チームを作る 2024/12](https://zenn.dev/2bo/articles/ai-product-team-by-autogen) -->

<!-- [AutoGenについて調査してみた](https://note.com/dev_onecareer/n/n9823d7f50254) -->

<!--------------------------------------------------------------------------------------------------------------------->
## Google：Vertex AI Agent Builder

Vertex AI Agent Builder の主な特徴をまとめると：

基本機能：


対話型AIエージェントの構築と展開
エンタープライズデータとの統合
マルチチャネルでの対話サポート（Web、モバイル、チャット等）


エージェントの種類：


Datastore Agent - 企業データに基づく質問応答
Task Agent - 特定のタスク実行に特化
Conversational Agent - 自然な対話型インターフェース


マルチエージェント対応：


現時点では、複数エージェント間の直接的な協調機能は明示的には提供されていない
個々のエージェントは独立して動作する設計


主な用途：


カスタマーサービス自動化
社内ナレッジベースへのアクセス
ビジネスプロセスの自動化
データ駆動型の意思決定支援


特徴的な機能：


ノーコード/ローコード開発環境
エンタープライズデータとの安全な統合
リアルタイムのモニタリングと性能調整
PaLM 2/Geminiモデルとの統合

Vertex AI Agent Builderは、Microsoft Copilot Studioと同様に、個別のAIエージェントの開発と展開に焦点を当てており、現時点ではAutoGenのような複数エージェントの動的な協調機能は主要な機能として提供していないようです。


[AI チャットの登場によって、そのビジネスモデルの今後が危ぶまれている Google](https://forbesjapan.com/articles/detail/76686) ですが、それゆえ（というよりそれ以前からも）、AI 関連には猛烈に投資をしています。そもそも [ChatGPT 実現の鍵となった ブレイクスルー技術「Transformer」](https://exawizards.com/column/seminar-report/chatgpt-transformer/) の [発案者が Google の研究者だった](https://wired.jp/article/sz-eight-google-employees-invented-modern-ai-transformers-paper/) ことは皮肉です。

Google は、AI エージェント構築システムとしては、**「Vertex AI Agent Builder」** を 2024年4月に発表しており、これを使うと、簡単なものなら ノーコードで AI エージェント・アプリケーションの構築が可能です。

![google-vertex-screen-1](/images/ai-agent-today-rev-1/google-vertex-screen-1.png =500x)

このシステムの 僕的なポイント は以下の２点です：
- **既存のビジネスプロセスを エージェントが模倣** しやすくすることにフォーカスしている
- **Google Cloud サービスとの連携** が容易

では、その実際をもう少し詳しく見ていきましょう。[Google の説明](https://cloud.google.com/products/agent-builder?hl=ja) によると（リンクをクリックして「Service Unavailable」と出た場合はブラウザの URL 表示部をクリックしてフォーカスを当て、リターンを押してみてください）：

- **自然言語を使用**して
- **インテリジェントな会話型 AI** と **プロセス自動化エージェント** を
- **設計、デプロイ、管理** する
- また **プロンプトベースのエージェント ビルダー ツール** と 
- **事前構築済みのテンプレート** を組み合わせることで
- **大量のコードを記述することなく、迅速なプロトタイピング、テスト、デプロイ** を実現

こういった点がハイレベルでの説明です。では、エージェント作成の実際を見つつ、その部分を深掘りしていきましょう。

#### Vertex AI Agent での AI エージェント 作成の実際

実際それがどういったものなのか知るには、以下のムービーを観るのが手っ取り早いです（全体で７分弱・2024年4月 公開）：

[![google-vertex-ai-movie-1](/images/ai-agent-today-rev-1/google-vertex-ai-movie-1.png =500x)](https://www.youtube.com/watch?v=cQfl3Nl3RXA&t=16s)

構築の基本的な進め方は、上述の Microsoft Copilot Studio と似ており、既存の汎用 チャット・エージェント をカスタマイズしていく、というアプローチです（1:00〜）。

Vertex AI では、AI エージェントの作成を、以下の２つの切り口で整理して進めます：
- **「Playbook」**
  - 特定のタスクを実行するために、ユーザとどうやり取りするかを定義
  - 具体的には Goal と Instructions（手順）を指定
- **「Tools」**
  - Playbook を外部システムと連携する手段
  - これにより、CRM システムや検索エンジンなどの外部データを、**ユーザとのやり取りの [グラウンディング（生成内容の裏付け）](https://atmarkit.itmedia.co.jp/ait/articles/2403/06/news027.html) に利用** できる

「Playbook」は、チャット・エージェントが特定のタスクに対処できるように、Goal、Instructions、Examples（対話例）を指定するものです（1:45〜）。

- **Goal（目的）：** Playbook が達成すべきことと、達成すべきではないこと（してはいけない類の返答など）を指定
- **Instructions（手順）：** エージェントが従うべき特定の手順（料理のレシピのようなもの）
- **Examples（例）：** エージェントの応答をユーザの応答に合わせて微調整するために使う、短いやり取りの例

そして Playbook から「Tools」を利用することにより、外部ソースを用いたグラウンディングを行ったり、外部システムへのトランザクションを実施したりできるようになります。

「Playbook」というアプローチを取った理由は、**既存のビジネスプロセスを容易に適用できるようにするため** です（2:40〜）。

ビジネスプロセスは、ステップに分けて定義され、各ステップでは、情報の入手、判断し、行動実施（外部データの更新など）を規定します。この手順を Playbook で模倣することにより、エージェントが人間の介入なしにゴールを達成することができるようにするため、とのことです。

![google-vertex-screen-2](/images/ai-agent-today-rev-1/google-vertex-screen-2.png =500x)

デモでは実際に、「WiFi トラブルシューター・エージェント」を、以下の手順で構築しています（3:15〜）。その様子を示した上のスクショでは、画面左側に「Goal」と「Instructions」用のテキストエリアが、右側には、挙動確認のための チャット・テスト・エリア が見えます。

1. 「WiFi トラブルシューティング・ガイド」を手元に用意する
2. Gemini（AI チャット）を使って、長い文章で記述されたガイドを「対応ステップの箇条書き」に変換する
3. これを「Playbook」の「Instructions（手順）」にコピペする
4. Goal にやること やらないことを書く
5. 以上で エージェントの作成は完了
6. チャット・テスト・エリアで、このエージェントに実際に質問し、順調に動いていることを確認
7. 例えば別の言語で回答するように挙動を変更するには、「Goal」にその旨指定する
8. また「例」を与えることにより、エージェントが特定の返答の仕方をするように調整できる
9. ここでは例示しなかったが、Tools を用いて外部リソースの利用もできる

より詳しい使い方については、以下のドキュメントが参考になります：

- [**「Dialogflow Vertex AI エージェント：エージェント アプリを作成する」**（Google）](https://cloud.google.com/dialogflow/vertex/docs/quick/create-application?hl=ja)（リンクをクリックして「Service Unavailable」と出た場合はブラウザの URL 表示部をクリックしてフォーカスを当て、リターンを押してみてください）
- [**「Vertex AI Agent Builder による Chat Bot の作り方」**（gihyo.jp 2024年9月）](https://gihyo.jp/article/2024/09/how-to-create-a-chatbot-using-an-ai-agent)


#### AI アシスタント構築フレームワーク

Googl は他に、 AI アシスタント（単体 AI エージェント）を構築するためのフレームワークとして「**Project Astra**」を公開しています。エージェント連携のためのフレームワークではないのですが、やや関連するので少し紹介します：

- [**Googl: Project Astra**（2024年5月）](https://ai-market.jp/services/what-project-astra/)
  - Gemini モデルベースの汎用 AI アシスタントを目指すプロジェクト
  - 視覚的入力（スマートグラスやモバイルカメラ）を通じて世界を理解し対話可能
  - Google 検索、マップ、レンズなどのサービスと統合して日常生活をサポート

<!--------------------------------------------------------------------------------------------------------------------->
## Amazon：Multi-Agent Orchestrator

クラウドサービスの雄、Amazon / AWS も、もちろん AI エージェント構築フレームワークを発表しています。[2024年12月に公開された **「Multi-Agent Orchestrator」**](https://www.infoq.com/jp/news/2024/12/aws-multi-agent/) です。Amazon の生成 AI サービス群をまとめた [「Amazon Bedrock」](https://aws.amazon.com/jp/bedrock/) の一部というポジショニングです。

「Multi-Agent Orchestrator」の 僕的なポイント は以下の3点です：

- **実際の組織の階層関係を模倣したマルチ・エージェントの明示的な役割管理**
- **AWS Lambda 等さまざまな AWS デプロイ環境とシームレスに統合可能**
- **オープンソース！[（GitHub で公開）](https://github.com/awslabs/multi-agent-orchestrator)**

![bedrock-demo](/images/ai-agent-today-rev-1/2024-bedrock-mac-demo.png =350x)

Amazon による「Multi-Agent Orchestrator」の概要説明は以下のとおりです：

- 専門的なスキルを必要とする複雑なマルチステップ・タスク（複雑な会話シナリオ）に、連携して取り組む複数の AI エージェントを構築、デプロイ、管理」するためのフレームワーク
- 「[Amazon Bedrock コンソール](https://console.aws.amazon.com/bedrock/) または [API](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html) を使用して、数ステップでスーパーバイザー（上司）エージェントを作成し、スペシャリスト（専門家）サブエージェントと連携させることができる

これも YouTube でデモが公開されていますので、その内容を追いながら、実際の使い方の理解を深めようと思います。


#### Multi-Agent Orchestrator での AI エージェント・システム 構築の実際

実際それがどういったものなのか知るには、以下のムービーを観るのが手っ取り早いです（全体で8分弱です）。
 [**「Multi-Agent Collaboration with Amazon Bedrock」**](https://www.youtube.com/watch?v=tMqTy1HR974)。

[![amazon-mao-movie-1](/images/ai-agent-today-rev-1/amazon-mao-movie-1.png =500x)](https://www.youtube.com/watch?v=tMqTy1HR974)


複数LLMを使ったワークフローの作成を、主にテキスト入力ベースで実現しているようです。
特徴としては、実際の会社組織を模倣したエージェント間の関係を構築するための、エージェント間の階層関係の管理に重きを置いていると思われる点があげられます。


より詳しく知りたい方は、例えば以下のドキュメントをご参照ください：

- [**「Amazon Bedrock のマルチエージェントコラボレーション機能の紹介 (プレビュー)」**（AWSSブログ 2024年12月）](https://aws.amazon.com/jp/blogs/news/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/)
- [**「Multi-Agent Orchestrator クイックスタートしてみた」**（Zenn 2024年11月） ](https://zenn.dev/o_kai/articles/e408dcad1a6536)


なお、Amazon は、AI 関係のサービスは[**「Amazon Bedrock」**](https://aws.amazon.com/jp/bedrock/)というブランドを全面に出しています。Multi-Agent Orchestrator もそのサービスの１つです。歴史的経緯から URL は「`aws.amazon.com/bedrock`」と、AWS の下にありますが、上述の Microsoft 同様、Amazon も AI 関連サービスを、AWS の下位のサービスではなく、AWS の次にくる独立した大きなビジネスの柱と捉えていることがわかります。


#### AI アシスタント構築フレームワーク

Amazon は他に、 AI アシスタント（単体 AI エージェント）を構築するためのフレームワークとして「**Amazon Q**」を持っています。エージェント連携のためのフレームワークではないのですが、やや関連するので少し紹介します：

- [**Amazon Q**（2023年11月）](https://aws.amazon.com/q/)
  - エンタープライズ向けの AI アシスタントで、AWS 内のサービスやリソースと直接連携可能
  - 企業の内部データやツールに接続し、セキュリティを保ちながら業務特化型の支援を提供
  - マルチモーダル対応で、コード生成からインフラ管理まで幅広いタスクに対応可能


<!--------------------------------------------------------------------------------------------------------------------->
## IBM：watsonx Orchestrate



[10分で分かる、watsonx Orchestrateの主要機能のご紹介](https://video.ibm.com/playlist/682425/video/133503510)

Salesforce操作や、Product Upsell（顧客が以前購入した商品と同種で「より上位のもの」を提案すること） メール作成、メール送信

- 特定のクロスセル条件を満たす顧客をSalesforceで検索
  - 操作にスキルが必要、時間がかかる
  - → チャット・インターフェースを提供
- 各顧客に提供する最適なクロスセル商品を決定
  - 専門的な商品知識が必要、時間がかかる
  - → AI による自動化
- 各顧客にパーソナライズされたメールを送信
  - 時間がなくテンプレートを使う場合が多く、結果顧客に無視される
  - → 顧客情報と商品詳細をAI生成モデルで処理。メールを自動で作成し送信
- 以上を複数のアプリを切り替えて実施
  - アプリを切り替える際、コピー＆ペースト等でエラーが発生する可能性
  - → データの受け渡しに人間が介在しない

チャット・インターフェースで、ステップにそって指示を出していく

アップセル・クロスセルを例に、単一化されたインターフェイス内で一連のスキルをシーケンス化することで、エージェントの業務を合理化し、生産性を高めてエラーを減らし、より価値の高い業務に集中できるようにした。

![ibm-watosonx-orchestrate](/images/ai-agent-today-rev-1/ibm-watosonx-orchestrate.png =600x)


[アップセル・クロスセルとは？](https://willof-work.co.jp/salesmedia/article/4439/)



<!--------------------------------------------------------------------------------------------------------------------->
## OpenAI：Swarm

- [**OpenAI、AI がブラウザ操作して 人を代行する「Operator」**（ImpressWatch 2025年1月）](https://www.watch.impress.co.jp/docs/news/1657120.html)
  - **AIがブラウザを操作し、タスクを実行するAI エージェント**
  - 用途としては、Webの入力や食料品の注文など、ブラウザ上で繰り返し行なうタスクの処理をOperatorに依頼
  - 人間が使用しているのと同じインターフェースやツールを使用できるため、AIの有用性が広がり、人々の日常的なタスクに費やす時間を節約できる

- [**ChatGPTの新機能「Scheduled tasks」徹底解説**（ChatGPTlab 2025年1月）](https://chatgpt-lab.com/n/naa1eb9becb85)
  - ユーザーが指定した時間や頻度に合わせてChatGPTが自動的にタスクを実行し、結果やリマインダーを通知してくれる新機能
  - **“自律的に行動するAI エージェント” に向けた一つのステップ** として位置付け

Swarm (experimental, educational)

人間工学に基づいた軽量なマルチエージェント・オーケストレーションを探求する教育的フレームワーク。

Requires Python 3.10+

Swarmは、エージェントの調整と実行を、軽量で、高度に制御可能で、容易にテスト可能にすることに重点を置いています。

これは、2つの原始的な抽象化によって達成される： エージェントとハンドオフです。エージェントは、命令とツールを包含し、いつでも他のエージェントに会話を引き継ぐことができます。

これらのプリミティブは、ツールやエージェントのネットワーク間の豊かなダイナミクスを表現するのに十分強力であり、急な学習曲線を避けながら、スケーラブルで実世界のソリューションを構築することができます。

Swarmは、軽量でスケーラブル、そしてデザインによって高度にカスタマイズ可能なパターンを探求している。Swarmに似たアプローチは、単一のプロンプトにエンコードすることが困難な、独立した多数の能力や命令を扱う状況に最適である。

Assistants APIは、完全にホストされたスレッドと、組み込みのメモリ管理と検索を求める開発者にとって、素晴らしい選択肢である。しかし、Swarmはマルチエージェント・オーケストレーションについて学びたい開発者にとっては教育的なリソースだ。Swarm は（ほぼ）完全にクライアント上で実行され、Chat Completions API のように、呼び出しの間に状態を保存しません。

[github](https://github.com/openai/swarm)


2024年10月に公開
Oct 15, 2024 のコミットが最後

[OpenAI の Swarm でエージェントオーケストレーションの仕組みを理解する](https://developer.mamezou-tech.com/blogs/2024/12/04/openai-swarm-multi-agent-intro/)

[OpenAIの「Swarm」でAIエージェントを開発してみた](https://zenn.dev/dalab/articles/1d4f649c8005a0)

[- Swarm - OpenAIの新しいマルチエージェント・フレームワークが誕生](https://qiita.com/ryosuke_ohori/items/ab292301f6baecf42d13)

![openai-swarm_diagram](/images/ai-agent-today-rev-1/openai-swarm_diagram.png =500x)

![openai-swarm-usage-example](/images/ai-agent-today-rev-1/openai-swarm-usage-example.png =500x)



#### AI アシスタント（単体 AI エージェント）構築フレームワーク

- [**OpenAI: Assistants API**（2023年11月）](https://platform.openai.com/docs/assistants/overview)
  - アプリ内への AIアシスタントの組込み・カスタマイズを可能にする API
  - コード実行、ファイル操作、外部ツール連携などの機能をモジュール化して提供
  - 会話履歴の管理やスレッド機能により、複雑な対話セッションの維持が可能



<!--------------------------------------------------------------------------------------------------------------------->
## Meta：Llama Stack

**「オープンソース（オープンパラメータ）LLM」の世界を切り開き、AI コミュニティ（[特に Hugging Face](https://huggingface.co/models)）と LLM の発展に絶大な貢献をした Meta** ですが、

> ご参考：
> ・[『Meta が LLM をオープンにする理由、UNIX 没落の教訓と「アンチ Apple」』（日経XTECH 2024年7月）](https://xtech.nikkei.com/atcl/nxt/column/18/00692/072500137/)
> ・[「Meta はなぜ AI をオープンソース化したのか。そして現在開発中の AI とは（PC Watch 2024年10月）」](https://pc.watch.impress.co.jp/docs/news/1629937.html)


AI エージェント構築関連では、**「Llama Stack」** と呼ばれるフレームワークを 2024年9月に発表しました。「モデルのカスタマイズとデプロイメントを簡素化するための包括的なツールセットで、多様な計算環境に対応するAPI 群」とのことです。

API 群という意味で LangChain と大枠同じ路線ですが（つまり**利用にはプログラミングが必要** / Llama Stack は Python のみをサポート）、「前処理モジュール」「モデルトレーニング」「デプロイメントモジュール」を備えている点にその特徴が見えます。

以下は、提供する API のコンポーネント群を図示したものです：

![meta-llama-stack](/images/ai-agent-today-rev-1/meta-llama-stack.png =500x)

「Llama Stack」についてのより突っ込んだ説明としては[「**AIエージェント分野でもメタが存在感、「Llama Stack」が与える強烈インパクト**（ビジネス+IT 2025年1月）」](https://www.sbbit.jp/article/cont1/155161) が詳しいです。
以下にその要点をまとめます：

- エージェントの調整と実行を、軽量で、高度に制御可能で、容易にテスト可能にすることに重点
- LangChainは、API やツール、データソースと LLM を接続するワークフローの調整に焦点を当てている。一方、LlamaIndex は外部データソースの統合と効率的なクエリ実行に特化
- Llama モデルに特化した統合エコシステムとして機能する。データ処理、トレーニング、推論などのタスク効率化に加え、前処理モジュール、モデルトレーニング／推論モジュール、デプロイメントモジュールを備える
- 構築されるアプリケーションは、タスクを分解して多段階の推論を行い、検索やコードインタープリターなどの組み込みツールを使用
- API 群は具体的には、推論、セーフティ、メモリ、エージェントシステム、評価、ポストトレーニング、合成データ生成、報酬スコアリングなど
- **AWS、Databricks、デル、Google Cloud、IBM watsonx、マイクロソフトのAzure、オラクルクラウド（OCI）、Snowflakeなど、25社以上のエコシステムパートナーと協力関係を構築**
<!-- - Dell Technologies が発表（2024年5月）した AI開発のためのインフた「Dell AI Factory」（AWS対抗）で採用 -->

技術的な詳細を知りたい方は[「**本家の説明資料**」](https://llama-stack.readthedocs.io/en/latest/index.html)をご参照ください。
[**GitHub のリポジトリはこちら**](https://github.com/meta-llama/llama-stack)です。
「Llama Stack」を利用するコードの雰囲気は以下のような感じです：

[![meta-llama-stack-code](/images/ai-agent-today-rev-1/meta-llama-stack-code.png =500x)](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html)



<!--------------------------------------------------------------------------------------------------------------------->
## Anthropic：Computer Use / Model Context Protocol

OpenAI の 因縁のライバルである Anthropic（詳細は たとえば [こちらのドキュメント](https://note.com/mikenerian/n/n0044d23dfa67) を参照）は、AI エージェント構築環境自体はまだリリースしていませんが、AI エージェント関連で、２件、注目すべき技術を発表しています。

### パソコン操作を自動化する「Computer Use」

１つ目は、**パソコン操作を自動化する「Computer Use」**。2024年10月に発表され、本当に大いに話題になりました（上述のように、追って OpenAI も同様な（より実用的な）「Operator」を 2025年1月に発表しました）。

「Computer Use」の概要や周辺情報については以下の記事が詳しいです：

- [**「AIによる「パソコン操作の自動化」最前線　Anthropicが一歩リード、マイクロソフトやグーグルも注目」**（Yahooニュース / AMP 2025年1月）](https://news.yahoo.co.jp/articles/7a0b2ca98a297664bbb6b5f6a16a7dec1e9956cb)
  - この機能により、AIエージェントはパソコンのスクリーンショットを通じて画面を「見て」理解し、マウス操作やキーボード入力を行うことができるようになる
  - すでにGitLab、Canva、Replitなどの企業が、この新機能の活用を開始
  - 特定のワークフローやソフトウェアに限定されず、様々なアプリケーションに対応できる柔軟性を備えている点で、従来の自動化ツールとは一線を画す


AI エージェント界隈の一部の人たちは、**ビジョンを介したコンピュータ操作の自動化が、AI エージェントを次のステップに飛躍させる大きな起爆剤になる**と考えています。**日常使っているアプリを（外部連携用の口が提供されていなくても）普段人間が操作するように、画面から直接操作できるようになる**、これはどういうことかというと、人手で処理していた色々なコンピュータ上の作業（アプリ操作）を自動化できるようになる、ということです。

つまりは、**極端に言えば、「コンピュータを使って定型業務をしている人を代行する AI エージェント」が作れちゃう**ことを意味します。



このインパクトは絶大で、僕も実際に試してみたのですが（[GitHub にソースが公開されている](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)ので `ANTHROPIC_API_KEY` を持っていて Docker がインストールされていれば **誰でも試せます**）、結構感動しました！

ちょっと長いですが、あまりに衝撃で、これを伝えずに AI エージェントの未来は語れないと思うので、その様子を以下で紹介します。

1. まずデモを起動すると、Linux が立ち上がった画面がブラウザに見えます（Docker 内で Linux を動かして VNC でブラウザに画面を飛ばしています）：
![anthropic-computer-use-1](/images/ai-agent-today-rev-1/anthropic-computer-use-1.png =500x)
2. 画面左側のチャット入力から **「ブラウザを開いて」** と日本語で指示すると、以下のように返答しつつ、Linux を操作し始めます：
   - 「はい、Firefoxブラウザを開きましょう。まず現在の画面の状態を確認して、Firefoxアイコンの位置を特定します。」
      `Tool Use: computer / Input: {'action': 'screenshot'}`
   - 「Firefoxのアイコンが画面下部にありますので、クリックして開きます。以下の手順で実行します：」
      `Input: {'action': 'mouse_move', 'coordinate': [804, 736]}`
      `Input: {'action': 'left_click'}`
   - 「Firefoxが起動しました。… これから何かウェブサイトを開きたい場合は、アドレスバーに直接URLを入力することができます。…
![anthropic-computer-use-2](/images/ai-agent-today-rev-1/anthropic-computer-use-2.png =500x)
1. **「CNNが見たい」**
   - 「はい、CNNのウェブサイトを開きましょう。アドレスバーをクリックしてCNNのURLを入力します。」
   - 「CNNのウェブサイトが表示されました。現在のトップニュースやその他の最新ニュースを見ることができます。…
![anthropic-computer-use-3](/images/ai-agent-today-rev-1/anthropic-computer-use-3.png =500x)
1. **「日本のニュースを表示して」**
   - 「はい、CNNの日本関連のニュースを探してみましょう。…
   - 「画面上部のニュース項目の中に "Japan sinkhole"（日本の陥没）についてのニュースが見えます。このニュースをクリックして詳細を見てみましょう：」
   - 「日本の陥没事故に関するニュースが表示されました。記事のタイトルは「A sinkhole swallowed a truck driver in Japan. It's expanding and residents are worried」（日本で陥没が truck driver を飲み込んだ。陥没は拡大しており、住民は心配している）というものです。…
![anthropic-computer-use-4](/images/ai-agent-today-rev-1/anthropic-computer-use-4.png =500x)

簡単なデモでしたが、**どれも雑な指示ながら、それを実現するための具体的な操作ステップを見出して、それを順に実施し、目的を達成していく**という…

**ほぼ、人間相手に指示を出している感覚**です… 😳

このデモでは、コンピュータ環境は、限定されたアプリがインストールされた Linux でしたが、**もし 業務用 PC でこれを動かせたら**（もちろんセキュリティとか色々課題はありますが）…
妄想が膨らみます…

<!-- > ちなみにこのデモは画像を多く扱うため、調子に乗って遊びまくるとすぐ上限に達します… -->

### AI エージェントの適用範囲を劇的に拡大する「MCP：Model Context Protocol」

これは 上の「Computer Use」に比べるとかなり地味ではありますが、僕は大きな可能性を感じている技術です。

**Model Context Protocol（MCP）は、たとえ提供元が異なった AI エージェントであっても、外部ツールやリソースを共用できるようにして、生成 AI（AI エージェント）のエコシステムを劇的に拡大するためのオープンソース技術** で、2024年11月に発表されました。

AI エージェントの実現のための重要な要素技術として「外部ツール呼び出し」があり、MCP はその可能性を広げるものなのですが、従来の、例えば [OpenAI の Function Calling](https://zenn.dev/kazuwombat/articles/1f39f003298028) や、[Claude の Tool Calling](https://zenn.dev/ttks/articles/b7115073a5712c)と本質的に何が違うの？ という疑問を持った方もいらっしゃるのではないでしょうか。

そこで、特にこれらと比較しての MCP アーキテクチャの特徴をまとめてみました：
- **オープンソース**：機能（Tool）を提供する方（MCPサーバ）も、利用する方（MCPクライアント）も、プロトコルや SDK が公開されていて、無料で利用可能（[Python SDK](https://github.com/modelcontextprotocol/python-sdk) / [TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)）
- **実装の明確な分離と再利用性**：明確に定義された通信プロトコルを介して機能（MCPサーバ）の実装が完全に分離されており、その独立性と再利用性が非常に高い。
- **利用側の拡張性**：MCPクライアントは、すべての MCPサーバで共通で、どのような MCPサーバーにも対応できる。つまり、どんな LLM アプリであっても、MCPクライアントさえ最初に組み込んでおけば、さまざまな機能を持った MCPサーバに対応でき、アプリ側の設定次第で、後から新規機能（新しい MCPサーバ）を追加利用することもできる。
- **アプリ間の相互運用性**：また上記のことは、MCPクライアントを組み込んだ すべてのアプリの間で、すべての MCPサーバが共通に利用できることも意味する。
- **リモート・リソース・アクセス（将来）**：将来的には、ネットワーク越しのリソース（MCPサーバ）への直接アクセスができるようになるらしい。目下絶賛作業中らしい（[ロードマップによる](https://modelcontextprotocol.io/development/roadmap)）

以上のような特徴のおかげで、上述のように、オープンソース・コミュニティで広く受け入れられ、非常に活発に開発が進められています。

発表されてからまだそんなに経っていない MCP ですが、既に多数の MCPサーバが、開発・公開されています。たとえば、Google Drive、Slack、Notion、Spotify、Docker、PostgreSQL などなど… ウェブ検索やブラウザ・オートメーション、DB アクセス、クラウド・サービス利用、SNS 連携 を含め、驚くほど多くの種類があります。以下に MCPサーバのまとめサイトをご紹介します：

- [Glama’s list of Open-Source MCP servers](https://glama.ai/mcp/servers)
- [awesome-mcp-servers](https://github.com/hideya/awesome-mcp-servers#Server-Implementations)
- [Smithery: MCP Server Registry](https://smithery.ai/)
- [MCP公式サイトの MCPサーバの例](https://modelcontextprotocol.io/examples)

![mcp-diagram-plain](/images/mcp-introduction/mcp-server-listing-sites.png =650x)

また [ロードマップ](https://modelcontextprotocol.io/development/roadmap) には、**リモートMCP接続** に加え、**「リモート MCPサーバーのディスカバリー（発見）と 接続方法 の定義」** が含まれています。

これはつまり、**現在、多くのウェブ・サービスが API を公開して、それをアプリが利用しているのと同じように、多くのウェブ・サービスが MCPサーバを公開して、さまざまな AI アプリ が必要に応じてそれらを「ディスカバー（発見）」して利用できるようになる** ことを意味しています。

この方向で妄想を膨らませると、例えば、**エージェント自身が、環境や状況の変化に対応するために新たな機能が必要になった際、そのことを自ら認識し、その機能をネット上から探し出して自身を拡張するような「自律進化型 AI エージェント」へとつながる可能性を秘めている** と考えることもできると思います（やや妄想気味ですが）。

そんなこともあって、僕はこの MCP に大いに注目しています（詳しくは、もしよろしければ [こちらをご覧ください](https://zenn.dev/h1deya/articles/mcp-introduction)）。

<!-- 他にも、NTTデータの「[SmartAgent](https://www.nttdata.com/jp/ja/trends/data-insight/2024/1224/)」とか似たコンセプトのものが多数あります。 -->

<!-- 要は、こういったマルチ・エージェント環境構築フレームワークの可能性（次の話題でもある「構築したAIシステム」の可能性も含めて）に色々な企業が注目して投資しており、今後ますます開発と適用が進みそうだということです。 -->



<!--------------------------------------------------------------------------------------------------------------------->
## その他の注目すべきプロジェクト

<!-- Anthropic関連：Claude Capabilities（2023年3月）: https://www.anthropic.com/claude -->

#### 業界動向

- [**Salesforce: Agentforce**（2024年10月一般提供開始）](https://www.salesforce.com/products/einstein/overview/#agentforce)
  - 自律型AIエージェント・スイート
  - ビジネス機能全般に対応する特化型エージェント群

- [**SAP: Joule Studio**（2024年Q4リリース）](https://www.sap.com/products/technology-platform/generative-ai.html)
  - SAP Build プラットフォーム上のローコード/ノーコード AI エージェント開発環境
  - 複数の AI エージェントが協調してワークフローを実行

- [**Oracle : GenAI for CX**](https://www.oracle.com/artificial-intelligence/generative-ai/)
  - カスタマーエクスペリエンス向けの生成AIエージェント
  - ヘルスケアアプリケーション向けの特化機能

#### プラットフォーム：

- [**Microsoft: Visual Studio Code AI**（2023年5月）](https://code.visualstudio.com/blogs/2023/03/30/vscode-copilot)
  - コード生成・レビュー・リファクタリング

- [**GPT Engineer** (2023年6月発表)](https://github.com/gpt-engineer-org/gpt-engineer)
  - ソフトウェア開発に特化したAIエージェント
  - 要件から自動的にコードベースを生成
  - プロジェクト構造の設計から実装まで一貫して実行

- [**MetaGPT** (2023年7月発表)](https://github.com/geekan/MetaGPT)
  - ソフトウェア開発チームをシミュレートするマルチエージェントフレームワーク
  - プロダクトマネージャー、アーキテクト、プログラマーなど、役割別のエージェントが協調
  - ソフトウェア開発プロセス全体を自動化

- [**CrewAI** (2023年12月発表)](https://github.com/joaomdmoura/crewAI)
  - 複数のエージェントの協調作業を実現するフレームワーク
  - 役割と目標を柔軟に定義可能
  - タスクの依存関係を考慮した並列実行が可能

- [**OpenAgents** (2023年10月発表)](https://github.com/xlang-ai/OpenAgents)
  - Webブラウザ上で動作する汎用AIエージェントプラットフォーム
  - データ分析、Web操作、コーディングなど多様なタスクに対応
  - ユーザーフレンドリーなインターフェースを提供

- [**Lyzr Automata**（2024年1月）](https://github.com/lyzr-ai/lyzr-automata)
  - マルチエージェントオートメーションフレームワーク 
  - 並列実行可能な特化型エージェントの構築に特化
  - Human-in-Loopメカニズムを中心に複雑な自動化プロセスを実現

- [**GitHub: Copilot Enterprise**（2024年2月）](https://github.com/features/preview/copilot-enterprise)
  - 企業向けカスタマイズ可能なAIペアプログラミング

これらは、単一のAIエージェントから、複数のエージェントが協調して作業を行うマルチエージェントシステムへと発展する流れを示しています。特に、ソフトウェア開発やチーム作業のシミュレーションに焦点を当てた技術が増えているのが特徴です。
これらの多くはオープンソースで開発が進められており、活発なコミュニティによって継続的に改善が行われています。



これらの最新動向から、以下のトレンドが見えてきます：

大手エンタープライズソフトウェア企業が、独自のAIエージェントプラットフォームの提供を開始
マルチエージェント協調による複雑なワークフロー自動化への注力
業界特化型のAIエージェントソリューションの増加
ローコード/ノーコードでのエージェント開発環境の提供



<!--------------------------------------------------------------------------------------------------------------------->
# 今的な AI エージェントの定義とその構築時の要点

以上、実際の製品例をとおして「AI エージェント環境構築フレームワーク」について理解を深めてきましたが、具体的なイメージがわかったところで、少し概念的な話をまとめたいと思います。

最初の方では、AI エージェントとは「特定の目標を達成するために構築された AI システム」と、やや緩めに定義しましたが、今注目され、大きなお金が動いているているのは「**個々の AI エージェントを組み合わせて構築した システム全体としての AI エージェント**」です。

Gartner ではそのような AI エージェント・システムを以下のように定義しています：
[「**デジタルおよびリアルの環境で、状況を知覚し、意思決定を下し、アクションを起こし、目的を達成するために AI技法を適用する自律的または半自律的なソフトウェア**」](https://www.gartner.co.jp/ja/newsroom/press-releases/pr-20250114-ai-agent) 


AI エージェントが持つ特徴は、[以下のようにもまとめられます](https://news.microsoft.com/ja-jp/2024/12/18/241218-operational-efficiency-and-innovation-enabled-by-ai-agents-latest-case-studies-from-japan/)：
- **自律性：** 与えられた目標に基づき自律して行動し、ユーザーの介入を最小限に抑える
- **目標指向：** 特定の目標やタスクの達成に向けて計画を立て、行動する
- **高度な推論：** 複雑で連続した対話からタスクを処理する能力を持ち、必要に応じて複数のエージェントと協調して問題を解決する

では、そのような **AI エージェント・システムを構築するためのアプローチに、何か良い枠組みはあるのでしょうか？**

そこで、注目され始めたのが、企業における **迅速な意思決定・行動を行うためのフレームワークとして評価の高い「[OODA ループ](https://www.keyence.co.jp/ss/general/manufacture-tips/ooda-loop.jsp)」を AIシステム構築に流用した枠組み** です。

つまり、AI エージェント環境構築フレームワークを用いてシステムを構築する際、**以下のそれぞれのステップに着目しながら、エージェント・システムを構築**していきます：

1. **Observe：環境観察・前提整理**
    - スケジュールやタスクの進行状況、社内環境や要件の変化など、作業環境を把握します
2. **Orient：状況判断と必要情報の取得**
    - 観察結果から状況を判断し、意思決定に必要な材料を洗い出し、それらを収集します
      - デジタル環境では、DB などの外部リソースやツールからの情報の収集
      - リアル環境では、カメラといった外部センサーからの情報の取得
3. **Decide：意思決定**
    - 上で得られた材料をもとに、具体的な方策や手段に関する意思決定を行います
    - プロンプト・エンジニアリングが要となります
4. **Act：実行**
    - 意思決定したことを実行に移します
      - デジタル環境では、外部ツールの利用や外部リソースの更新
      - リアル環境では、機器の制御など


すなわち、AI エージェントは、OODAループを回すという、**非常に実務的な領域に突入し始めている**のです。

次の最後の節では、実際の適用事例を眺めながら、実用段階に突入した AIエージェントの息吹を感じ取っていただければと思います。




<!--------------------------------------------------------------------------------------------------------------------->
# 参考資料：企業動向・適用事例・経済効果・etc.

以上、AI エージェントについて、包括的・網羅的・具体的に見てきました。
AI エージェントまわりは、本当に動きが激しいです。
そこでご参考までに、僕が最近気になった AI エージェント 関連のネット記事を、少し長いですが以下に列挙し、要点を引用します。今後の AI エージェント適用の方向性や可能性を感じ取っていただければ幸いです。

[**「AI エージェントの事例5選、ウォルマート、NEC、NTTデータの “面白い活用法” を解説」**（ビジネス+IT 2024年12月）](https://www.sbbit.jp/article/cont1/152258)
  1. **博報堂テクノロジーズの「ブレストAI」**
    従来であれば… 適した人材の時間を確保する必要があったが… 参加する人材の時間調整を含む、プロセス全体を効率化
  1. **パナソニック コネクトの「個人特化AI」**
    自社公開情報をAIに参照させながら固有の情報を回答させる「自社特化AIの活用」… 年間 18.6万時間という膨大な労働時間を生成AI活用で削減
  1. **NTTデータの「次の時代のSIer論」**
    自律的にそのタスクの前段階の段取り（日程調整・連絡実施等）を行い、複数のタスク結果を総合して目的を遂行する「デジタルレイバー型」へと深化させる取り組み
  2. **ウォルマートの「取引先と交渉するAI」**
    膨大な数のサプライヤー… 1社1社と価格交渉や納期調整などに多くの時間やリソースを割いている… こうした複数主体との交渉・調整をAI エージェント同士に任せる… スタッフだけでは数週間から数カ月かかっていた仕入先との交渉を数日に短縮できている
  3. **NECの「AI エージェント同士の交渉」**
    通常、必要な部品を希望納期に間に合わせるように調達交渉するとなれば、1週間はかかるほどの煩雑な仕事となるが、自動交渉AIであれば数十秒で実現できる。


[**「進化するアクセンチュア、AI エージェント同士が商談」**（日経ビジネス 2025年1月）](https://business.nikkei.com/atcl/gen/19/00710/012300002/)
- **三井物産は社内の AI 同士を連携させ複雑な業務を自動化**
- **アクセンチュアは AI 同士が商談する未来描く**
- **有益なデータ与え続け AI を賢く育てた会社が勝つ時代に**


[**「ヤンマーが挑む「社員クローン」、AI エージェント実装段階に」**（日経ビジネス 2025年1月）](https://business.nikkei.com/atcl/gen/19/00710/012300001/)
- **予想よりはるかに早くAIが人間の知性を超えつつある**
- **様々なシステムを操り、誰にも頼らずに仕事を完遂する**


[**「NVIDIAも焦点当てる「エージェントAI」、すでに「前例ない」レベルで利益を生み出すほどの影響力」**（Yahooニュース / AMP 2024年12月）](https://news.yahoo.co.jp/articles/e5445ad4c61f2b83f8e9b78b184da906db363a19)
- ガートナーの最新予測によると、**2024年時点で1％未満に過ぎないエージェントAIの企業向けソフトウェアアプリケーションへの組み込み率は、2028年までに33％に達する見込み**
- これにより、**日々の業務における意思決定の15％が自律的に遂行される可能性**がある
- Capgemini が大手企業幹部 1,100名を対象に実施した最新の調査によれば
  - **すでに10％の組織がAIエージェントを活用**
  - **82％が3年以内の導入を予定**
  - **71％がエージェントAIによってワークフローの自動化が促進**
  - **64％が顧客サービスと満足度が改善**
  - **57％が生産性向上のメリットがリスクを上回ると評価**
- IDCの最新レポート「The Global Impact of Artificial Intelligence on the Economy and Jobs」
  - **AIの採用や既存業務へのAI活用、AIを活用した製品・サービス提供に向けた企業の投資が、2030年までに累積で19兆9,000億ドルの経済効果をもたらすと試算**
  - **2030年には世界GDPの3.5％を占めるまでに成長すると予測**
  - **AIソリューションとサービスへの新規投資1ドルあたり、間接的・誘発的効果として4.60ドルの経済効果が生まれると分析**
- 保険ブローカー企業の事例
  - AIエージェントチームは、商業マネージャー、保険数理・引受機能、会計士、カスタマーケアマネージャー、ITスタッフなど、多岐にわたる役割を担当
  - 3カ月という短期間でチームが立ち上がり、**保険金請求率の目標を2倍上回る成果を上げた**
  - **人件費、福利厚生費、給与税などが運用費用の約65％を占める保険ブローカー業界において、AIエージェントの導入によりこれらのコストをゼロに抑制**することにも成功
- NVIDIAは、2030年までに社員（現在約3万人）を5万人に拡大しつつ、**1億人分のAIエージェントを構築する計画**


[**「マイクロソフトやNTTデータなど続々参入　まずは定型業務の自動化から」**（日経ビジネス 2025年1月）](https://business.nikkei.com/atcl/NBD/19/special/02035/)
- **世界のAIエージェント市場は30年に、24年比で9倍超の471億ドル（約7兆3000億円）に達する見通し**（インドのマーケッツ・アンド・マーケッツ調べ）
- 業務ソフトを手掛ける米サービスナウも先ごろAIエージェント市場に参入「人口減が進む日本では、不足する労働力を補うことになるだろう」


[**「アクセンチュア、業界に特化したAI エージェントの導入を加速し、業務プロセスの変革を実現する AI Refinery for Industry を発表」**（PRTIMES 2025年1月）](https://prtimes.jp/main/html/rd/p/000000426.000019290.html)
- 業界固有のビジネスプロセスや高度な専門性を踏まえて体系化
- **各企業のデータを使用してカスタマイズできる専門マルチエージェントネットワークの導入も加速**


[**「“実在する人間” の考えをクローンした 自律 AI を1000体以上生成。高い精度で世論調査や社会の反応予測など活用へ」**（TechnoEdge 2024年11月）](https://www.techno-edge.net/article/2024/11/25/3862.html)
- 各個人に対して 2時間のインタビューを実施し、そのデータを基に一人一人の行動や思考をシミュレートできるように創り込み
- **自律 AI は 元の参加者（人間）が 2週間後に同じ質問に答えた際の一貫性と比較して、85%という高い精度**を達成
- 注目すべき点は、このシステムが単なる人口統計データや簡単な人物描写ではなく、**詳細なインタビューデータを用いることで、より正確な予測を可能にした**こと


[**『「Azure OpenAI Service OpenAI o1」や「GitHub Copilot」などの生成AIをマイグレーションに活用する「マイグレーションAI エージェント サービス」を開始』**（ヘッドウォータース / PRTIIMES 2024年11月）](https://prtimes.jp/main/html/rd/p/000000192.000018045.html)
- レガシーシステムから最新のクラウド環境へと移行するマイグレーションが企業にとっては不可欠
- 特に **COBOL などの古いプログラミング言語に精通したエンジニアが 2025年までに数多く引退** することが予測
- **マイグレーションプロセスの自動化に生成 AI を活用することによって、効率化の低下や IT 人材不足といった課題を解決**


[**「ソニー・ホンダモビリティが新型EV「アフィーラ1」を「CES 2025」で発表」**（WebCG 2025年1月）](https://www.webcg.net/articles/-/51393)
- 高度なエージェント機能　… **AI技術により、「Perception（認識）」「Prediction（予測）」「Planning（行動計画）」の各工程で高度な運転支援**」

<!-- [AI エージェントとは何かをやさしく解説、安野貴博氏が語るChatGPTとの違いやメリット](https://www.sbbit.jp/article/cont1/137047) -->

<!-- [Gartner、2025年の戦略的テクノロジのトップ・トレンドを発表（Gartner 2024年10月）](https://www.gartner.co.jp/ja/newsroom/press-releases/pr-20241028-techtrends) -->

<!-- [Intelligent Agents in AI Really Can Work Alone. Here’s How](https://www.gartner.com/en/articles/intelligent-agent-in-ai) -->


<!--------------------------------------------------------------------------------------------------------------------->
# おわりに

以上、AI エージェントの現状について、現時点での僕の理解をベースにまとめてみました。
いつもとっ散らかった文章に、最後までお付き合いいただき、どうもありがとうございます 🙇‍♂️
何か勘違いや分かりにくい部分があったら、ぜひコメントくださいませ 🙇‍♂️
もし何らかのご参考になることがあったのであれば、とってもうれしいです 😀

> いや本当に今回こそは、サクッと簡潔に書き上げるつもりだったのです…
> 本当に書きたい内容は「AI エージェントの未来ビジョンの妄想とアイデア」で、その前段階として「AI エージェントの現状でもまとめておくか」と、書き始めたのですが…
> 現状を調べるにつけ「いっそこれを自分用の備忘録、調査メモにしちゃおう」と思ったが最後、メモっておきたい事がどんどん増えてしまって…
> 仕事の仕方、悪過ぎだと思う… 😓
> > 将来的には、こういったレポートの類も、AI エージェントがサクッと書いちゃうのかな…？
> > もしそうなったら全面的にぜひお任せしたい！ もの書きは僕の本業ではないので…

<!--------------------------------------------------------------------------------------------------------------------->

<!-- [LLMやAIエージェントの潮流とその先の展望（電通総研 2024年12月）](https://www.dentsusoken.com/case_report/research/20241223/2811.html) -->

<!-- [AI連携とオーケストレーションのための基盤ビジョンLLM（NEC技報 2023年3月）](https://jpn.nec.com/techrep/journal/g23/n02/230218.html) -->

<!-- [グラウンディング（Grounding）とは？その意味とビジネスへの影響](https://www.salesforce.com/jp/blog/jp-what-is-grounding/) -->

<!--------------------------------------------------------------------------------------------------------------------->
